# Phase 6 — Adaptive Intelligence & Strategy Evolution

**Objective:** Transform the system into a self-improving autonomous trading researcher. It should observe its own performance, mutate and evolve strategies, discover new signal combinations, and re-tune models automatically — creating a closed-loop that learns, experiments, and redeploys better agents continuously.

## 1 — Core goals

Build an autonomous experimentation framework ("Evolution Engine") that:

- Monitors daily performance of all strategies and parameter sets.
- Automatically proposes new configurations (mutations, crossovers, new features).
- Backtests and paper-runs them in controlled sandboxes.
- Promotes outperformers to active status.

Create a knowledge layer that captures what has been learned — why winners win — and reuses those insights for future designs.

Use AI models (LLMs or tabular ML) to generate hypotheses and reason about performance drivers.

Allow the system to "explain its own evolution" to you via the assistant dashboard.
- Deliver a Phase 6 autonomous evolution dashboard in Next.js, expanding the Evolution Lab with experiment orchestration controls, knowledge base viewers, and persistent light/dark theming using Tailwind + shadcn.

## 2 — New components

| Component | Purpose |
|-----------|---------|
| `evolution/engine.py` | Orchestrates continuous experimentation, mutation, evaluation |
| `evolution/mutator.py` | Generates candidate strategy variations |
| `evolution/evaluator.py` | Runs backtests / paper-runs and scores results |
| `evolution/promoter.py` | Promotes best candidates to production, retires underperformers |
| `knowledge/base.py` | Stores metadata, feature importances, parameter histories, causal notes |
| `ai/hypothesis_agent.py` | LLM-driven reasoning: interprets metrics, suggests mutations |
| `dashboard/evolution_view` | Visual dashboard for ongoing experiments, mutations, promotions |

## 3 — High-level workflow

1. **Observe:** Collect all recent runs' metrics (PnL, Sharpe, drawdown, hit rate, latency, etc.).
2. **Select:** Rank strategies by ROI and stability.
3. **Mutate:** Create new variants — change features, horizons, model types, hyperparameters, thresholds, or trade management rules.
4. **Simulate:** Run each variant through paper backtests using stored OHLCV data.
5. **Evaluate:** Score and compare variants using ROI, Sharpe, max drawdown, and statistical significance.
6. **Promote:** Replace the weakest live strategies with the best-performing candidates.
7. **Explain:** Use LLM to summarize what was learned: _"Winners this week favored short-term volatility compression on BTC and avoided ETH leverage > 3×."_
8. **Iterate:** Repeat daily or weekly.

## 4 — Strategy genome schema

A `StrategyGenome` represents one specific configuration.

```json
{
  "id": "genome-ETH-scalper-v12",
  "base_symbol": "ETH/USDT",
  "horizon": "1h",
  "model_type": "LGBM",
  "features": ["rsi_14", "ema_20", "volatility_5m", "trend_strength"],
  "params": {
    "stop_loss_pct": 0.015,
    "take_profit_pct": 0.03,
    "leverage": 3,
    "entry_signal": "rsi_cross_30",
    "exit_signal": "ema_crossover"
  },
  "training_window": "90d",
  "eval_metrics": {
    "roi": 0.042,
    "sharpe": 1.5,
    "hit_rate": 0.61,
    "max_drawdown": 0.07
  },
  "parent_ids": ["genome-ETH-scalper-v11"],
  "status": "active",
  "created_at": "2025-11-04T10:00:00Z"
}
```

## 5 — Mutation engine

### 5.1 Mutation operations

| Operation | Example |
|-----------|---------|
| Parameter perturbation | Vary `stop_loss_pct` ± 0.002 |
| Feature addition/removal | Add `bollinger_band_width` or drop `ema_50` |
| Horizon mutation | Try 30m or 4h instead of 1h |
| Model swap | Switch from LightGBM to Transformer forecaster |
| Rule crossover | Combine entry of genome A with exit of genome B |

### 5.2 Generation logic

```python
def generate_mutations(base_genome, num_variants=10):
    variants = []
    for _ in range(num_variants):
        g = deepcopy(base_genome)
        op = random.choice(["param_shift", "feature_add", "feature_drop", "horizon_change"])
        g.apply_mutation(op)
        g.id = new_id()
        variants.append(g)
    return variants
```

### 5.3 Safety

- Only mutate non-critical parameters automatically.
- Larger structural changes (new exchanges, high leverage) require manual approval.

## 6 — Evaluation system

### 6.1 Metrics computed

- ROI, Sharpe, Sortino, max drawdown, trade hit rate, avg hold time, exposure time, slippage cost.
- Weight metrics by stability (penalize high variance).

### 6.2 Evaluation flow

1. Backtest or paper-run for N simulated days.
2. Compute metrics → normalized score 0–1.
3. Compare to parent's score.
4. Store results + lineage in `evolution_results` collection.
5. Mark top X% as promotable candidates.

## 7 — Knowledge base

A `knowledge_base` Mongo collection storing learnings per week:

| Field | Description |
|-------|-------------|
| `period` | e.g., "2025-11-W1" |
| `winners_summary` | JSON summary of high performers |
| `losers_summary` | JSON summary of low performers |
| `insights` | LLM-generated text of discovered relationships |
| `actionables` | suggestions (e.g., "reduce leverage on ETH scalpers") |
| `feature_correlations` | dict of feature → ROI correlation |
| `stored_embeddings` | optional vector embeddings for similarity search |

LLM (`ai/hypothesis_agent.py`) will generate weekly insight docs by reading aggregated metrics and producing summaries like:

> _"During this week, high-frequency BTC scalpers underperformed due to widening spreads. Strategies with volatility normalization achieved +3.4% higher ROI. Suggest testing adaptive spread filters."_

## 8 — Promotion & deployment policy

### Promotion criteria:

- Score > parent score × (1 + ε)
- Sharpe > 1.0, Drawdown < 0.15
- At least 2 weeks of stable paper results

### Promotion flow:

1. Mark parent as archived
2. Activate new genome in live/paper schedule
3. Update assistant to know about new genome
4. Log rationale in `evolution_log`

## 9 — Dashboard extensions

**"Evolution Lab"** page in Next.js dashboard:

- Real-time display of running experiments
- Graph of genome lineage tree (with ROI color scale)
- Buttons: View insights, Promote manually, Archive
- Metrics summary + weekly evolution report

### Frontend scope (Phase 6 UI)

**New / Updated Pages**
- `/evolution/autonomy` (new) — Autonomous Evolution Dashboard with experiment kanban, scheduler controls, knowledge timeline; consumes `GET /api/evolution/experiments`, `PATCH /api/evolution/experiments/{id}`, `GET /api/evolution/schedulers`, `POST /api/evolution/schedulers/toggle`.
- `/settings/autonomy` (new) — Configure auto-promote thresholds, safety limits, knowledge retention policies via `GET/PUT /api/settings/autonomy`.
- `/knowledge` (new) — Knowledge base browser with timeline + search hooking into `GET /api/knowledge/search`, `GET /api/knowledge/{period}`.
- `/assistant` — Adds "What changed this week?" quick action that calls `POST /api/assistant/query` with evolution context.

**Key Components**
- `ExperimentKanbanBoard`, `ExperimentCard`, `ExperimentDetailPanel` (with lineage breadcrumbs + metrics).
- `SchedulerStatusBadge`, `SchedulerConfigModal`, `AutomationToggle`.
- `KnowledgeTimeline`, `InsightCard`, `InsightActionBar`, `KnowledgeSearchInput`.
- `AutonomyAlertDrawer`, `RollbackModal`, `SafetyGuardSummary`.

**Backend Integrations**
- Evolution engine: `GET /api/evolution/experiments`, `PATCH /api/evolution/experiments/{id}`, `POST /api/evolution/promote`, `POST /api/evolution/rollback`.
- Scheduler management: `GET /api/evolution/schedulers`, `POST /api/evolution/schedulers/toggle`, `PUT /api/evolution/schedulers/config`.
- Knowledge base: `GET /api/knowledge/search`, `GET /api/knowledge/{period}`, `POST /api/knowledge/pin`.
- Settings: `GET/PUT /api/settings/autonomy`, `POST /api/settings/autonomy/test` (dry-run safety checks).
- Notifications: WebSocket `/ws/evolution` for real-time experiment updates.

**UX & QA**
- Kanban drag-and-drop supports pointer + keyboard interactions (aria attributes, roving tabindex).
- Real-time updates display skeleton placeholders and subtle toasts when experiments transition states.
- Knowledge timeline provides filters (symbol, strategy family) and exports insights to PDF/Markdown using server API.
- Playwright suite verifying auto-promote toggle, scheduler modal save, knowledge search highlight, and theme parity.
- Storybook coverage for `ExperimentCard`, `KnowledgeTimeline`, `AutonomyAlertDrawer`.

## 10 — AI reasoning integration

### 10.1 Hypothesis agent tasks

- Review all weekly metrics.
- Identify anomalies (_"X strategy failed only on Thursdays → low volume pattern"_).
- Suggest new feature combinations (_"add volatility ratio between ETH/BTC"_).
- Explain changes in a human-readable paragraph.

### 10.2 Prompt sketch

```
You are the research analyst for a quant lab.
Given the JSON data of all strategies and metrics for the last 7 days,
1. Identify top 3 reasons why winners won.
2. Identify top 3 reasons why losers failed.
3. Propose 3 new hypotheses or modifications to test next week.
Return concise bullet list + short summary paragraph.
```

## 11 — Scheduling & automation

**Cron jobs:**

- `daily_evolution` (generate & evaluate candidates)
- `weekly_analysis` (run hypothesis agent + produce report)
- `promotion_job` (auto-promote candidates passing thresholds)

Configurable via YAML so you can throttle compute usage.

## 12 — Monitoring & safety

- Track CPU/GPU usage, ensure evolution runs off-hours.
- Alert if too many mutations degrade performance (> 10% drop week-over-week).
- Implement rollback: restore prior "known-good" genomes from backup.

## 13 — Testing & validation

- **Unit:** test mutation validity (all parameters within allowed bounds).
- **Integration:** simulate full evolution cycle on small dataset and verify one genome promoted.
- **Regression:** ensure newly promoted strategies outperform baseline in at least 2 key metrics.

## 14 — Security & isolation

- Run evolution jobs in isolated worker environment (Docker sandbox).
- No real trading until manual approval of promotion.
- Sandbox accounts cannot access live API keys.

## 15 — Acceptance criteria (Phase 6 complete)

- ✅ Automated evolution engine produces new candidate genomes daily.
- ✅ Evaluations scored and stored; top performers can be promoted semi-automatically.
- ✅ Knowledge base contains weekly insight summaries.
- ✅ Assistant can answer "What did we learn this week?" with grounded evidence.
- ✅ System passes safety thresholds (no auto-promotion to live without confirmation).
- ✅ Evolution dashboard visualizes lineage and performance progression.
- ✅ Autonomous Evolution Dashboard frontend includes experiment board, knowledge viewer, and controls with accessible Tailwind + shadcn theming.
- ✅ Settings page persists autonomy guard rails through `/api/settings/autonomy`.

## 16 — Implementation snapshot

- Evolution engine (`evolution/engine.py`) orchestrates mutation, evaluation, promotion, and knowledge recording with scheduler state persisted via MongoDB.
- Mutation system extends genome metadata (features, horizon, model) while reusing Phase 2 genetics — see `evolution/mutator.py`.
- Evaluations reuse the simulator pipeline and write back metrics + scores for promotion policies in `evolution/evaluator.py` and `evolution/promoter.py`.
- Knowledge base service (`knowledge/base.py`) captures weekly summaries, feature correlations, and invokes the LLM-backed hypothesis agent (`ai/hypothesis_agent.py`) with deterministic fallback.
- FastAPI routes expose evolution controls, scheduler toggles, knowledge search, and autonomy settings including `/api/evolution/*` and `/api/settings/autonomy`.
- Celery gains an `run_autonomous_evolution` task for scheduled cycles.
- Frontend adds the Autonomous Evolution dashboard (`/evolution/autonomy`), Autonomy settings (`/settings/autonomy`), and Knowledge browser (`/knowledge`) with new shadcn components for Kanban, scheduler status, alerts, and timeline views.
- Assistant quick action “What changed this week?” targets the evolution knowledge base.